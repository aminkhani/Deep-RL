{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys \n",
    "import numpy as np\n",
    "import gym # gym version: 0.21.0\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid cell state and color mapping\n",
    "EMPTY = BLACK = 0\n",
    "WALL = GRAY = 1\n",
    "AGENT = BLUE = 2\n",
    "BOMB = RED = 3\n",
    "GOAL = GREEN = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB color value table\n",
    "COLOR_MAP = {\n",
    "    BLACK : [0.0, 0.0, 0.0],\n",
    "    GRAY : [0.5, 0.5, 0.5],\n",
    "    BLUE : [0.0, 0.0, 1.0],\n",
    "    RED : [1.0, 0.0, 0.0],\n",
    "    GREEN : [0.0, 1.0, 0.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action mapping\n",
    "NOOP = 0\n",
    "DOWN = 1\n",
    "UP = 2\n",
    "LEFT = 3\n",
    "RIGHT= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv(gym.Env):\n",
    "    def __init__(self, max_steps=100) -> None:\n",
    "        \"\"\"Initialize Gridworld\n",
    "\n",
    "        Args:\n",
    "            max_steps (int, optional): Max steps per episode. Defaults to 100.\n",
    "        \"\"\"\n",
    "        # Observations\n",
    "        self.grid_layout = \"\"\"\n",
    "        1 1 1 1 1 1 1 1\n",
    "        1 2 0 0 0 0 0 1\n",
    "        1 0 1 1 1 0 0 1\n",
    "        1 0 1 0 1 0 0 1\n",
    "        1 0 1 4 1 0 0 1\n",
    "        1 0 3 0 0 0 0 1\n",
    "        1 0 0 0 0 0 0 1\n",
    "        1 1 1 1 1 1 1 1 \n",
    "        \"\"\"\n",
    "        self.initial_grid_state = np.fromstring(self.grid_layout, dtype=int, sep=\" \")\n",
    "        self.initial_grid_state = self.initial_grid_state.reshape(8, 8)\n",
    "        self.grid_state = copy.deepcopy(self.initial_grid_state)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=6, shape=self.grid_state.shape)\n",
    "        self.img_shape = [256, 256, 3]\n",
    "        self.metadata = {\"renfer.mode\" : [\"human\"]}\n",
    "        # Actions\n",
    "        self.action_space = gym.spaces.Discrete(5)\n",
    "        self.actios = [NOOP, DOWN, UP, LEFT, RIGHT]\n",
    "        self.action_pos_dict = defaultdict(\n",
    "            lambda : [0, 0],\n",
    "            {\n",
    "                NOOP: [0, 0],\n",
    "                UP: [-1, 0],\n",
    "                DOWN: [1, 0],\n",
    "                LEFT: [0, -1],\n",
    "                RIGHT: [0, 1],\n",
    "            }\n",
    "        )\n",
    "        (self.agent_state, self.goal_state) = self.get_state()\n",
    "        self.step_num = 0  # To keep track of number of steps\n",
    "        self.max_steps = max_steps\n",
    "        self.done = False\n",
    "        self.info = {\"status\": \"Live\"}\n",
    "        self.viewer = None\n",
    "    def get_state(self):\n",
    "        start_state = np.where(self.grid_state == AGENT)\n",
    "        goal_state = np.where(self.grid_state == GOAL)\n",
    "\n",
    "        start_or_gloal_not_found = not (start_state[0] and goal_state[0])\n",
    "        if start_or_gloal_not_found:\n",
    "            sys.exit(\n",
    "                \"Start and/or Goal state not present in the Gridworld. \"\n",
    "                \"Check the Grid layout\"\n",
    "            )\n",
    "        start_state = (start_state[0][0], start_state[1][0])\n",
    "        goal_state = (goal_state[0][0], goal_state[1][0])\n",
    "        return start_state, goal_state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Return next observation, reward, done, info\"\"\"\n",
    "        action = int(action)\n",
    "        reward = 0.0\n",
    "\n",
    "        next_state = (\n",
    "            self.agent_state[0] + self.action_pos_dict[action][0],\n",
    "            self.agent_state[1] + self.action_pos_dict[action][1]\n",
    "        )\n",
    "        next_state_invalid = ((next_state[0] < 0 or next_state[0] >= self.grid_state.shape[0]) or\n",
    "                             (next_state[1] < 1 or next_state[1] >= self.grid_state.shape[1]))\n",
    "        if next_state_invalid: \n",
    "            # Leave the agent state unchanged\n",
    "            next_state = self.agent_state\n",
    "            self.info[\"status\"] = \"Next state is invalid\"\n",
    "\n",
    "        next_agent_state = self.grid_state[next_state[0], next_state[1]]\n",
    "\n",
    "        # Calculate Reward\n",
    "        if next_agent_state == EMPTY:\n",
    "            # Move agent from previous state to new state on the grid\n",
    "            self.info[\"status\"] = \"Agent move to a new cell\"\n",
    "            self.grid_state[next_state[0], next_state[1]] = AGENT\n",
    "            self.grid_state[self.agent_state[0], self.agent_state[1]] = EMPTY\n",
    "            self.agent_state = copy.deepcopy(next_state)\n",
    "\n",
    "        elif next_agent_state == WALL:\n",
    "            self.info['status'] = \"Agent bumped into a wall\"\n",
    "            reward = -1\n",
    "        # Terminal state\n",
    "        elif next_agent_state == GOAL:\n",
    "            self.info['status'] = \"Agent reached the GOAL\"\n",
    "            self.done = True\n",
    "            reward = +1\n",
    "        elif next_agent_state == BOMB:\n",
    "            self.info['status'] = 'Agent stepped on a BOMB'\n",
    "            self.done = True\n",
    "            reward = -1\n",
    "        # elif next_agent_state == AGENT:\n",
    "        else:\n",
    "            # NOOP or next state is invalid\n",
    "            self.done = False\n",
    "\n",
    "        self.step_num += 1\n",
    "\n",
    "        # Check if max steps per episode has been reached\n",
    "        if self.step_num > self.max_steps:\n",
    "            self.done = True\n",
    "            self.info['status'] = 'Max steps reached'\n",
    "\n",
    "        if self.done:\n",
    "            done = True\n",
    "            terminal_state = copy.deepcopy(self.grid_state)\n",
    "            terminal_info = copy.deepcopy(self.info)\n",
    "            _ = self.reset()\n",
    "            return (terminal_state, reward, done, terminal_info)\n",
    "\n",
    "        return self.grid_state, reward, self.done, self.info   \n",
    "\n",
    "    def reset(self):\n",
    "        self.grid_state = copy.deepcopy(self.initial_grid_state)\n",
    "        (self.agent_state, self.goal_state) = self.get_state()\n",
    "        self.step_num = 0\n",
    "        self.done = False\n",
    "        self.info[\"status\"] = \"Live\"\n",
    "        return self.grid_state\n",
    "\n",
    "    def gridarray_to_image(self, img_shape=None):\n",
    "        if img_shape is None:\n",
    "            img_shape = self.img_shape\n",
    "        observation = np.random.randn(*img_shape) * 0.0\n",
    "        scale_x = int(observation.shape[0] / self.grid_state.shape[0])\n",
    "        scale_y = int(observation.shape[1] / self.grid_state.shape[1])\n",
    "        for i in range(self.grid_state.shape[0]):\n",
    "            for j in range(self.grid_state.shape[1]):\n",
    "                for k in range(3):  # 3-channel RGB image\n",
    "                    pixel_value = COLOR_MAP[self.grid_state[i, j]][k]\n",
    "                    observation[\n",
    "                        i * scale_x : (i + 1) * scale_x,\n",
    "                        j * scale_y : (j + 1) * scale_y,\n",
    "                        k,\n",
    "                    ] = pixel_value\n",
    "        return (255 * observation).astype(np.uint8)\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        if close:\n",
    "            if self.viewer is not None:\n",
    "                self.viewer.close()\n",
    "                self.viewer = None\n",
    "            return\n",
    "        img = self.gridarray_to_image()\n",
    "        if mode == \"rgb_array\":\n",
    "            return img\n",
    "        elif mode == \"human\":\n",
    "            from gym.envs.classic_control import rendering\n",
    "            if self.viewer is None:\n",
    "                self.viewer = rendering.SimpleImageViewer()\n",
    "            self.viewer.imshow(img)\n",
    "\n",
    "    def close(self):\n",
    "        self.render(close=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_action_meanings():\n",
    "        return [\"NOOP\", \"DOWN\", \"UP\", \"LEFT\", \"RIGHT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step#:1 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:2 reward:-1 done:False info:{'status': 'Agent bumped into a wall'}\n",
      "step#:3 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:4 reward:-1 done:False info:{'status': 'Agent bumped into a wall'}\n",
      "step#:5 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:6 reward:-1 done:False info:{'status': 'Agent bumped into a wall'}\n",
      "step#:7 reward:-1 done:False info:{'status': 'Agent bumped into a wall'}\n",
      "step#:8 reward:0.0 done:False info:{'status': 'Next state is invalid'}\n",
      "step#:9 reward:-1 done:False info:{'status': 'Agent bumped into a wall'}\n",
      "step#:10 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:11 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:12 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:13 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:14 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:15 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:16 reward:0.0 done:False info:{'status': 'Agent move to a new cell'}\n",
      "step#:17 reward:-1 done:True info:{'status': 'Agent stepped on a BOMB'}\n"
     ]
    }
   ],
   "source": [
    "env = GridWorldEnv(max_steps=500)\n",
    "obs = env.reset()\n",
    "done = False\n",
    "step_num = 1\n",
    "# Run one episode\n",
    "while not done:\n",
    "    # Sample a random ac?tion from the action space\n",
    "    action = env.action_space.sample()\n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "    print(f\"step#:{step_num} reward:{reward} done:{done} info:{info}\")\n",
    "    step_num += 1\n",
    "    img = env.render(mode='rgb_array')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20580e28dc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a03b173d79384e175d8841e46ebdd0829bb82735538c862c665e9640e41fed0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
